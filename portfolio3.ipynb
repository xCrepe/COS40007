{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfTZmr6d4pz8",
        "outputId": "8fdd71fd-303c-4a26-d3e8-60b1d410b6fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The cuml.accel extension is already loaded. To reload it, use:\n",
            "  %reload_ext cuml.accel\n"
          ]
        }
      ],
      "source": [
        "%load_ext cuml.accel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "XHZWfKJM4t7h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier, export_text\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd00dEV85MEv"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GOQ8ktBs5O2T"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('vegemite.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZYZ2eIf6-iF"
      },
      "source": [
        "Shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueyr8G7X5eF7",
        "outputId": "346a0541-573b-41c3-dadc-f00fd8d8a7ea"
      },
      "outputs": [],
      "source": [
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0w43h7J2d"
      },
      "source": [
        "Check class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZZNZ_Pr7Hcm",
        "outputId": "76a2ecb9-bec7-4cfa-d53a-c4a23001f114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in full dataset:\n",
            "Class\n",
            "0    2642\n",
            "1    5047\n",
            "2    7548\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "target_col = df_shuffled.columns[-1]\n",
        "print(f\"Class distribution in full dataset:\")\n",
        "print(df_shuffled[target_col].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35otdEP67OQA"
      },
      "source": [
        "Extract balanced test set: at least 300 samples from each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jsPKU1b7Q9w",
        "outputId": "e783aca5-01c8-4776-d900-e28a2d7af94b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set shape: (1002, 47)\n",
            "Test set class distribution:\n",
            "Class\n",
            "0    334\n",
            "1    334\n",
            "2    334\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Training set shape: (14235, 47)\n",
            "Training set class distribution:\n",
            "Class\n",
            "0    2308\n",
            "1    4713\n",
            "2    7214\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "test_samples = []\n",
        "train_samples = []\n",
        "\n",
        "for class_label in sorted(df_shuffled[target_col].unique()):\n",
        "    class_data = df_shuffled[df_shuffled[target_col] == class_label]\n",
        "\n",
        "    n_test = min(334, len(class_data))\n",
        "\n",
        "    class_train, class_test = train_test_split(\n",
        "        class_data,\n",
        "        test_size=n_test,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    test_samples.append(class_test)\n",
        "    train_samples.append(class_train)\n",
        "\n",
        "df_test = pd.concat(test_samples, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_train = pd.concat(train_samples, ignore_index=True).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"Test set shape: {df_test.shape}\")\n",
        "print(f\"Test set class distribution:\\n{df_test[target_col].value_counts().sort_index()}\")\n",
        "print(f\"\\nTraining set shape: {df_train.shape}\")\n",
        "print(f\"Training set class distribution:\\n{df_train[target_col].value_counts().sort_index()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmzzScgu-4ZL",
        "outputId": "03bf9c90-9734-4744-b7e5-a40fefb6d8d4"
      },
      "outputs": [],
      "source": [
        "df_test.to_csv('vegemite_test_1000.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kruT65iZ--bI"
      },
      "source": [
        "Check for constant value columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaMEtOyu-8zd",
        "outputId": "0b16ef06-a77c-4a88-9033-e41c82c347f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Constant value columns found: ['TFE Steam temperature SP', 'TFE Product out temperature']\n",
            "Removed 2 constant columns\n"
          ]
        }
      ],
      "source": [
        "constant_cols = []\n",
        "for col in df_train.columns[:-1]:\n",
        "    if df_train[col].nunique() == 1:\n",
        "        constant_cols.append(col)\n",
        "\n",
        "if constant_cols:\n",
        "    print(f\"Constant value columns found: {constant_cols}\")\n",
        "    df_train = df_train.drop(columns=constant_cols)\n",
        "    print(f\"Removed {len(constant_cols)} constant columns\")\n",
        "else:\n",
        "    print(\"No constant value columns found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5DX1BgoA9Wb"
      },
      "source": [
        "Check for columns with few integer values (categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HSQp6JZA7FO",
        "outputId": "1d44013b-1f73-4348-fc3a-d27ffac264d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns converted to categorical: ['FFTE Feed tank level SP', 'FFTE Pump 1', 'FFTE Pump 1 - 2', 'FFTE Pump 2', 'TFE Motor speed']\n"
          ]
        }
      ],
      "source": [
        "categorical_cols = []\n",
        "for col in df_train.columns[:-1]:\n",
        "    if df_train[col].dtype in ['int64', 'float64']:\n",
        "        unique_vals = df_train[col].nunique()\n",
        "        if unique_vals <= 10:\n",
        "            categorical_cols.append(col)\n",
        "            df_train[col] = df_train[col].astype('category')\n",
        "\n",
        "if categorical_cols:\n",
        "    print(f\"Columns converted to categorical: {categorical_cols}\")\n",
        "else:\n",
        "    print(\"No columns need categorical conversion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faiwSs-SBGpg"
      },
      "source": [
        "Check class balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkC8VZpA_Ss",
        "outputId": "325f2e6f-bb9c-4e59-8d15-4b3a0643d6c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution before balancing:\n",
            "Class\n",
            "0    2308\n",
            "1    4713\n",
            "2    7214\n",
            "Name: count, dtype: int64\n",
            "Class balance ratio: 0.32\n",
            "Applying SMOTE and undersampling...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after SMOTE:\n",
            "Class\n",
            "0    7214\n",
            "1    7214\n",
            "2    7214\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X = df_train.iloc[:, :-1]\n",
        "y = df_train.iloc[:, -1]\n",
        "\n",
        "print(f\"Class distribution before balancing:\")\n",
        "print(y.value_counts().sort_index())\n",
        "print(f\"Class balance ratio: {y.value_counts().min() / y.value_counts().max():.2f}\")\n",
        "\n",
        "if y.value_counts().min() / y.value_counts().max() < 0.8:\n",
        "    print(\"Applying SMOTE and undersampling...\")\n",
        "    cat_features = X.select_dtypes(include=['category']).columns\n",
        "    for col in cat_features:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col])\n",
        "\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "    print(f\"Class distribution after SMOTE:\")\n",
        "    print(pd.Series(y_balanced).value_counts().sort_index())\n",
        "else:\n",
        "    X_balanced, y_balanced = X, y\n",
        "    print(\"Classes are already balanced\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLT7yVGIBRgk"
      },
      "source": [
        "Create composite features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSCpsatQBSFM",
        "outputId": "c588fa83-6c7b-4094-d891-18ce6c0c99bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10 SP (setpoint) columns\n",
            "Found 34 PV (process variable) columns\n",
            "Created 4 composite features\n"
          ]
        }
      ],
      "source": [
        "composite_features = pd.DataFrame()\n",
        "\n",
        "sp_cols = [col for col in X_balanced.columns if 'SP' in col.upper()]\n",
        "pv_cols = [col for col in X_balanced.columns if 'PV' in col.upper() or ('SP' not in col.upper())]\n",
        "\n",
        "print(f\"Found {len(sp_cols)} SP (setpoint) columns\")\n",
        "print(f\"Found {len(pv_cols)} PV (process variable) columns\")\n",
        "\n",
        "numeric_cols = X_balanced.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 1:\n",
        "    composite_features['mean_all'] = X_balanced[numeric_cols].mean(axis=1)\n",
        "    composite_features['std_all'] = X_balanced[numeric_cols].std(axis=1)\n",
        "\n",
        "    sp_numeric = [col for col in sp_cols if col in numeric_cols]\n",
        "    if len(sp_numeric) > 1:\n",
        "        composite_features['mean_sp'] = X_balanced[sp_numeric].mean(axis=1)\n",
        "        composite_features['std_sp'] = X_balanced[sp_numeric].std(axis=1)\n",
        "\n",
        "    print(f\"Created {len(composite_features.columns)} composite features\")\n",
        "\n",
        "X_final = pd.concat([X_balanced.reset_index(drop=True), composite_features], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BH_zVAGBWTk"
      },
      "source": [
        "Final feature count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExuBNzCtBaqP",
        "outputId": "6c44d07f-d227-403d-a818-bac0ac6f784c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total features in final dataset: 48\n",
            "Original features: 44\n",
            "Composite features: 4\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total features in final dataset: {X_final.shape[1]}\")\n",
        "print(f\"Original features: {X_balanced.shape[1]}\")\n",
        "print(f\"Composite features: {composite_features.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE2s9i4uBpFd",
        "outputId": "3fa7fe56-522f-4094-ad9e-c0ff20b2aa0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed training data saved as 'vegemite_train_processed.csv'\n"
          ]
        }
      ],
      "source": [
        "df_train_processed = pd.concat([X_final, pd.Series(y_balanced, name=target_col)], axis=1)\n",
        "df_train_processed.to_csv('vegemite_train_processed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l67iOdtBwq2"
      },
      "source": [
        "Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyzTBNcSBrco",
        "outputId": "38830a46-8b45-4b85-8f72-897562afc71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 20 features using SelectKBest (f_classif)\n",
            "Selected features: ['FFTE Feed tank level SP', 'FFTE Production solids SP', 'TFE Out flow SP', 'TFE Vacuum pressure SP', 'FFTE Feed flow SP', 'FFTE Discharge density', 'FFTE Feed flow rate PV', 'FFTE Heat temperature 1', 'FFTE Temperature 1 - 1', 'FFTE Temperature 1 - 2']...\n",
            "Justification: Reduced features from 48 to 20\n",
            "This reduces overfitting and improves model generalization\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_final)\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=min(20, X_final.shape[1]))\n",
        "X_selected = selector.fit_transform(X_scaled, y_balanced)\n",
        "\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = X_final.columns[selected_mask].tolist()\n",
        "\n",
        "print(f\"Selected {len(selected_features)} features using SelectKBest (f_classif)\")\n",
        "print(f\"Selected features: {selected_features[:10]}...\")\n",
        "print(f\"Justification: Reduced features from {X_final.shape[1]} to {len(selected_features)}\")\n",
        "print(f\"This reduces overfitting and improves model generalization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfR__XDwBzAQ"
      },
      "source": [
        "Split data for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_odGuMimByvz",
        "outputId": "3f6d7811-fed1-430e-8ed3-a9eb07163f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set: (17313, 20)\n",
            "Validation set: (4329, 20)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_selected, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXh_UjQ2B7HN"
      },
      "source": [
        "Train multiple ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fjbmAAaB7YY",
        "outputId": "feb0172f-aef3-4efa-9539-b73ee2eeb76c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DecisionTree...\n",
            "DecisionTree trained successfully\n",
            "Training RandomForest...\n",
            "RandomForest trained successfully\n",
            "Training GradientBoosting...\n",
            "GradientBoosting trained successfully\n",
            "Training SVM...\n",
            "SVM trained successfully\n",
            "Training LogisticRegression...\n",
            "LogisticRegression trained successfully\n",
            "Training KNN...\n",
            "KNN trained successfully\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "    'DecisionTree': DecisionTreeClassifier(max_depth=10, min_samples_split=20, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', C=1.0, random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "    print(f\"{name} trained successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RexMS30CCW8A"
      },
      "source": [
        "Evaluate models and create comparison table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ALyyLxLKCYM6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: DecisionTree\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86      1443\n",
            "           1       0.83      0.81      0.82      1443\n",
            "           2       0.87      0.85      0.86      1443\n",
            "\n",
            "    accuracy                           0.85      4329\n",
            "   macro avg       0.85      0.85      0.85      4329\n",
            "weighted avg       0.85      0.85      0.85      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1277   88   78]\n",
            " [ 171 1162  110]\n",
            " [  69  152 1222]]\n",
            "\n",
            "\n",
            "Model: RandomForest\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97      1443\n",
            "           1       0.97      0.95      0.96      1443\n",
            "           2       0.98      0.96      0.97      1443\n",
            "\n",
            "    accuracy                           0.96      4329\n",
            "   macro avg       0.96      0.96      0.96      4329\n",
            "weighted avg       0.96      0.96      0.96      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1426   14    3]\n",
            " [  55 1366   22]\n",
            " [  28   33 1382]]\n",
            "\n",
            "\n",
            "Model: GradientBoosting\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      1443\n",
            "           1       0.97      0.97      0.97      1443\n",
            "           2       0.98      0.98      0.98      1443\n",
            "\n",
            "    accuracy                           0.98      4329\n",
            "   macro avg       0.98      0.98      0.98      4329\n",
            "weighted avg       0.98      0.98      0.98      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1423   14    6]\n",
            " [  24 1399   20]\n",
            " [   9   23 1411]]\n",
            "\n",
            "\n",
            "Model: SVM\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.88      0.80      1443\n",
            "           1       0.79      0.67      0.72      1443\n",
            "           2       0.79      0.76      0.77      1443\n",
            "\n",
            "    accuracy                           0.77      4329\n",
            "   macro avg       0.77      0.77      0.77      4329\n",
            "weighted avg       0.77      0.77      0.77      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1266   76  101]\n",
            " [ 285  969  189]\n",
            " [ 163  189 1091]]\n",
            "\n",
            "\n",
            "Model: LogisticRegression\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.60      0.54      1443\n",
            "           1       0.45      0.28      0.35      1443\n",
            "           2       0.51      0.58      0.54      1443\n",
            "\n",
            "    accuracy                           0.49      4329\n",
            "   macro avg       0.48      0.49      0.48      4329\n",
            "weighted avg       0.48      0.49      0.48      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[865 221 357]\n",
            " [591 406 446]\n",
            " [323 280 840]]\n",
            "\n",
            "\n",
            "Model: KNN\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94      1443\n",
            "           1       0.92      0.92      0.92      1443\n",
            "           2       0.96      0.90      0.93      1443\n",
            "\n",
            "    accuracy                           0.93      4329\n",
            "   macro avg       0.93      0.93      0.93      4329\n",
            "weighted avg       0.93      0.93      0.93      4329\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1404   27   12]\n",
            " [  72 1333   38]\n",
            " [  55   96 1292]]\n",
            "\n",
            "\n",
            "             Model  Accuracy  Precision   Recall  F1-Score\n",
            "  GradientBoosting  0.977824   0.977825 0.977824  0.977815\n",
            "      RandomForest  0.964195   0.964655 0.964195  0.964177\n",
            "               KNN  0.930700   0.931771 0.930700  0.930546\n",
            "      DecisionTree  0.845692   0.845759 0.845692  0.845451\n",
            "               SVM  0.768307   0.771294 0.768307  0.766212\n",
            "LogisticRegression  0.487641   0.481706 0.487641  0.475620\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    print(f\"Model: {name}\")\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    print(f\"{cm}\\n\\n\")\n",
        "\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'Precision': report['weighted avg']['precision'],\n",
        "        'Recall': report['weighted avg']['recall'],\n",
        "        'F1-Score': report['weighted avg']['f1-score']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(results)\n",
        "comparison_df = comparison_df.sort_values('F1-Score', ascending=False)\n",
        "print(comparison_df.to_string(index=False))\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmxyLQdVDFmH"
      },
      "source": [
        "Select best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "JH9KadH2DGnd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best performing model: GradientBoosting\n",
            "Justification: Highest F1-Score (0.9778)\n",
            "This model provides the best balance between precision and recall\n"
          ]
        }
      ],
      "source": [
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "print(f\"Best performing model: {best_model_name}\")\n",
        "print(f\"Justification: Highest F1-Score ({comparison_df.iloc[0]['F1-Score']:.4f})\")\n",
        "print(f\"This model provides the best balance between precision and recall\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq0c1ccmEdBU"
      },
      "source": [
        "Save the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "9ZynbGv-EctA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['selected_features.pkl']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "joblib.dump(best_model, 'best_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(selector, 'feature_selector.pkl')\n",
        "joblib.dump(selected_features, 'selected_features.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W0TOyJ0EiiE"
      },
      "source": [
        "ML TO AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "SC8chQwzEi6A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded test set: (1002, 47)\n",
            "Model and preprocessors loaded successfully\n"
          ]
        }
      ],
      "source": [
        "df_test_load = pd.read_csv('vegemite_test_1000.csv')\n",
        "print(f\"Loaded test set: {df_test_load.shape}\")\n",
        "\n",
        "loaded_model = joblib.load('best_model.pkl')\n",
        "loaded_scaler = joblib.load('scaler.pkl')\n",
        "loaded_selector = joblib.load('feature_selector.pkl')\n",
        "print(\"Model and preprocessors loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QubK50CjEpWV"
      },
      "source": [
        "Process each row and predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "GJhkb9olElIm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 0 rows...\n",
            "Processed 200 rows...\n",
            "Processed 400 rows...\n",
            "Processed 600 rows...\n",
            "Processed 800 rows...\n",
            "Processed 1000 rows...\n",
            "Total predictions made: 1002\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "for idx, row in df_test_load.iterrows():\n",
        "    X_row = row[:-1].values.reshape(1, -1)\n",
        "    y_actual = row.iloc[-1]\n",
        "\n",
        "    if constant_cols:\n",
        "        X_row = np.delete(X_row, [df_test_load.columns.get_loc(c) for c in constant_cols if c in df_test_load.columns], axis=1)\n",
        "\n",
        "    X_row_df = pd.DataFrame(X_row, columns=X_final.columns[:X_row.shape[1]])\n",
        "\n",
        "    if len(composite_features.columns) > 0:\n",
        "        composite_row = pd.DataFrame()\n",
        "        numeric_cols_test = X_row_df.select_dtypes(include=[np.number]).columns\n",
        "        if len(numeric_cols_test) > 1:\n",
        "            composite_row['mean_all'] = [X_row_df[numeric_cols_test].mean(axis=1).values[0]]\n",
        "            composite_row['std_all'] = [X_row_df[numeric_cols_test].std(axis=1).values[0]]\n",
        "\n",
        "            sp_numeric_test = [col for col in sp_numeric if col in numeric_cols_test]\n",
        "            if len(sp_numeric_test) > 1:\n",
        "                composite_row['mean_sp'] = [X_row_df[sp_numeric_test].mean(axis=1).values[0]]\n",
        "                composite_row['std_sp'] = [X_row_df[sp_numeric_test].std(axis=1).values[0]]\n",
        "\n",
        "        X_row_final = pd.concat([X_row_df, composite_row], axis=1)\n",
        "    else:\n",
        "        X_row_final = X_row_df\n",
        "\n",
        "    X_row_scaled = loaded_scaler.transform(X_row_final)\n",
        "    X_row_selected = loaded_selector.transform(X_row_scaled)\n",
        "\n",
        "    y_pred = loaded_model.predict(X_row_selected)[0]\n",
        "\n",
        "    predictions.append(y_pred)\n",
        "    actuals.append(y_actual)\n",
        "\n",
        "    if idx % 200 == 0:\n",
        "        print(f\"Processed {idx} rows...\")\n",
        "\n",
        "print(f\"Total predictions made: {len(predictions)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY1Sfl4WEzPC"
      },
      "source": [
        "Measure performance on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "mfRe71FNE0wP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.98      0.97       334\n",
            "         1.0       0.96      0.95      0.95       334\n",
            "         2.0       0.96      0.96      0.96       334\n",
            "\n",
            "    accuracy                           0.96      1002\n",
            "   macro avg       0.96      0.96      0.96      1002\n",
            "weighted avg       0.96      0.96      0.96      1002\n",
            "\n",
            "Confusion Matrix:\n",
            "[[326   3   5]\n",
            " [ 10 317   7]\n",
            " [  3  11 320]]\n",
            "\n",
            "Test Accuracy: 0.9611\n"
          ]
        }
      ],
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(actuals, predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(actuals, predictions))\n",
        "\n",
        "test_accuracy = accuracy_score(actuals, predictions)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3KPp63EE2tN"
      },
      "source": [
        "Compare all models on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "aVHMpGrbE65_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTree: Accuracy = 0.7764, F1-Score = 0.7761\n",
            "RandomForest: Accuracy = 0.9421, F1-Score = 0.9421\n",
            "GradientBoosting: Accuracy = 0.9611, F1-Score = 0.9610\n",
            "SVM: Accuracy = 0.3333, F1-Score = 0.1667\n",
            "LogisticRegression: Accuracy = 0.4202, F1-Score = 0.3239\n",
            "KNN: Accuracy = 0.8782, F1-Score = 0.8782\n",
            "\n",
            "Test Set Model Comparison:\n",
            "             Model  Test Accuracy  Test F1-Score\n",
            "  GradientBoosting       0.961078       0.961047\n",
            "      RandomForest       0.942116       0.942074\n",
            "               KNN       0.878244       0.878227\n",
            "      DecisionTree       0.776447       0.776141\n",
            "LogisticRegression       0.420160       0.323858\n",
            "               SVM       0.333333       0.166667\n",
            "\n",
            "GradientBoosting is still the best performer on test data\n"
          ]
        }
      ],
      "source": [
        "test_results = []\n",
        "for name, model in trained_models.items():\n",
        "    X_test_processed = []\n",
        "    for idx, row in df_test_load.iterrows():\n",
        "        X_row = row[:-1].values.reshape(1, -1)\n",
        "        if constant_cols:\n",
        "            X_row = np.delete(X_row, [df_test_load.columns.get_loc(c) for c in constant_cols if c in df_test_load.columns], axis=1)\n",
        "        X_row_df = pd.DataFrame(X_row, columns=X_final.columns[:X_row.shape[1]])\n",
        "\n",
        "        if len(composite_features.columns) > 0:\n",
        "            composite_row = pd.DataFrame()\n",
        "            numeric_cols_test = X_row_df.select_dtypes(include=[np.number]).columns\n",
        "            if len(numeric_cols_test) > 1:\n",
        "                composite_row['mean_all'] = [X_row_df[numeric_cols_test].mean(axis=1).values[0]]\n",
        "                composite_row['std_all'] = [X_row_df[numeric_cols_test].std(axis=1).values[0]]\n",
        "                sp_numeric_test = [col for col in sp_numeric if col in numeric_cols_test]\n",
        "                if len(sp_numeric_test) > 1:\n",
        "                    composite_row['mean_sp'] = [X_row_df[sp_numeric_test].mean(axis=1).values[0]]\n",
        "                    composite_row['std_sp'] = [X_row_df[sp_numeric_test].std(axis=1).values[0]]\n",
        "            X_row_final = pd.concat([X_row_df, composite_row], axis=1)\n",
        "        else:\n",
        "            X_row_final = X_row_df\n",
        "\n",
        "        X_row_scaled = loaded_scaler.transform(X_row_final)\n",
        "        X_row_selected = loaded_selector.transform(X_row_scaled)\n",
        "        X_test_processed.append(X_row_selected[0])\n",
        "\n",
        "    X_test_array = np.array(X_test_processed)\n",
        "    y_test_pred = model.predict(X_test_array)\n",
        "\n",
        "    acc = accuracy_score(actuals, y_test_pred)\n",
        "    report = classification_report(actuals, y_test_pred, output_dict=True)\n",
        "\n",
        "    test_results.append({\n",
        "        'Model': name,\n",
        "        'Test Accuracy': acc,\n",
        "        'Test F1-Score': report['weighted avg']['f1-score']\n",
        "    })\n",
        "\n",
        "    print(f\"{name}: Accuracy = {acc:.4f}, F1-Score = {report['weighted avg']['f1-score']:.4f}\")\n",
        "\n",
        "test_comparison_df = pd.DataFrame(test_results).sort_values('Test F1-Score', ascending=False)\n",
        "print(\"\\nTest Set Model Comparison:\")\n",
        "print(test_comparison_df.to_string(index=False))\n",
        "\n",
        "if test_comparison_df.iloc[0]['Model'] == best_model_name:\n",
        "    print(f\"\\n{best_model_name} is still the best performer on test data\")\n",
        "else:\n",
        "    print(f\"\\n{test_comparison_df.iloc[0]['Model']} performed best on test data\")\n",
        "    print(f\"Original selection {best_model_name} ranked #{test_comparison_df[test_comparison_df['Model']==best_model_name].index[0]+1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8EQTsRVE95D"
      },
      "source": [
        "DEVELOP RULES FROM ML MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "s6Eu2mwEE-SP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12 SP (setpoint) columns: ['FFTE Feed tank level SP', 'FFTE Production solids SP', 'FFTE Steam pressure SP', 'TFE Out flow SP', 'TFE Production solids SP', 'TFE Vacuum pressure SP', 'TFE Steam pressure SP', 'FFTE Feed flow SP', 'FFTE Out steam temp SP', 'TFE Motor speed', 'mean_sp', 'std_sp']\n",
            "\n",
            "Decision Tree Rules (SP Features):\n",
            "|--- std_sp <= 3234.26\n",
            "|   |--- std_sp <= 2958.06\n",
            "|   |   |--- FFTE Steam pressure SP <= 123.00\n",
            "|   |   |   |--- mean_sp <= 1165.11\n",
            "|   |   |   |   |--- TFE Out flow SP <= 2212.14\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- TFE Out flow SP >  2212.14\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- mean_sp >  1165.11\n",
            "|   |   |   |   |--- FFTE Out steam temp SP <= 49.32\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- FFTE Out steam temp SP >  49.32\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |--- FFTE Steam pressure SP >  123.00\n",
            "|   |   |   |--- TFE Out flow SP <= 2009.74\n",
            "|   |   |   |   |--- FFTE Production solids SP <= 40.20\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Production solids SP >  40.20\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- TFE Out flow SP >  2009.74\n",
            "|   |   |   |   |--- TFE Out flow SP <= 2282.98\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- TFE Out flow SP >  2282.98\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |--- std_sp >  2958.06\n",
            "|   |   |--- std_sp <= 2990.11\n",
            "|   |   |   |--- TFE Out flow SP <= 1885.46\n",
            "|   |   |   |   |--- mean_sp <= 1168.33\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- mean_sp >  1168.33\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- TFE Out flow SP >  1885.46\n",
            "|   |   |   |   |--- FFTE Production solids SP <= 41.49\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- FFTE Production solids SP >  41.49\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |--- std_sp >  2990.11\n",
            "|   |   |   |--- FFTE Out steam temp SP <= 50.13\n",
            "|   |   |   |   |--- FFTE Feed flow SP <= 10198.47\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- FFTE Feed flow SP >  10198.47\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- FFTE Out steam temp SP >  50.13\n",
            "|   |   |   |   |--- FFTE Steam pressure SP <= 127.58\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- FFTE Steam pressure SP >  127.58\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|--- std_sp >  3234.26\n",
            "|   |--- TFE Production solids SP <= 84.90\n",
            "|   |   |--- TFE Out flow SP <= 2146.97\n",
            "|   |   |   |--- TFE Production solids SP <= 64.00\n",
            "|   |   |   |   |--- FFTE Out steam temp SP <= 50.05\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |--- FFTE Out steam temp SP >  50.05\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- TFE Production solids SP >  64.00\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |--- TFE Out flow SP >  2146.97\n",
            "|   |   |   |--- FFTE Steam pressure SP <= 117.97\n",
            "|   |   |   |   |--- TFE Production solids SP <= 68.96\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- TFE Production solids SP >  68.96\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |--- FFTE Steam pressure SP >  117.97\n",
            "|   |   |   |   |--- TFE Out flow SP <= 2990.36\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |   |   |   |--- TFE Out flow SP >  2990.36\n",
            "|   |   |   |   |   |--- class: 2\n",
            "|   |--- TFE Production solids SP >  84.90\n",
            "|   |   |--- FFTE Feed tank level SP <= 1.00\n",
            "|   |   |   |--- TFE Production solids SP <= 86.50\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP <= -71.95\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- TFE Vacuum pressure SP >  -71.95\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- TFE Production solids SP >  86.50\n",
            "|   |   |   |   |--- class: 2\n",
            "|   |   |--- FFTE Feed tank level SP >  1.00\n",
            "|   |   |   |--- std_sp <= 3264.76\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- std_sp >  3264.76\n",
            "|   |   |   |   |--- class: 2\n",
            "\n",
            "\n",
            "Top 5 Most Important SP Features:\n",
            "                 Feature  Importance\n",
            "                  std_sp    0.283444\n",
            "         TFE Out flow SP    0.174474\n",
            "TFE Production solids SP    0.133517\n",
            "  FFTE Steam pressure SP    0.119272\n",
            "  FFTE Out steam temp SP    0.099010\n"
          ]
        }
      ],
      "source": [
        "sp_columns = [col for col in X_final.columns if 'SP' in col.upper()]\n",
        "print(f\"{len(sp_columns)} SP (setpoint) columns: {sp_columns}\")\n",
        "\n",
        "if len(sp_columns) > 0:\n",
        "    X_sp = X_final[sp_columns]\n",
        "\n",
        "    dt_sp = DecisionTreeClassifier(max_depth=5, min_samples_split=50, random_state=42)\n",
        "    dt_sp.fit(X_sp, y_balanced)\n",
        "\n",
        "    tree_rules = export_text(dt_sp, feature_names=sp_columns)\n",
        "    print(\"\\nDecision Tree Rules (SP Features):\")\n",
        "    print(tree_rules)\n",
        "\n",
        "    with open('decision_tree_rules.txt', 'w') as f:\n",
        "        f.write(tree_rules)\n",
        "\n",
        "    importances = pd.DataFrame({\n",
        "        'Feature': sp_columns,\n",
        "        'Importance': dt_sp.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 5 Most Important SP Features:\")\n",
        "    print(importances.head().to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rapids",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
